# Calculating Sentiment Value from list of article titles
# Analysis
# Import modules
import re
from collections import Counter
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Define a function to return titles from txt files as a list
def read_titles_from_file(filename):
    with open(filename, 'r') as file:
        titles = file.readlines()
    return [title.strip() for title in titles]

# Define a function to remove stop words from a list of titles (I found these stopwords on Google)
def remove_stopwords(title):
    stop_words = set([
        "i", "me", "my", "myself", "we", "our", "ours", "ourselves", "you", "your", "yours", "yourself", "yourselves",
        "he", "him", "his", "himself", "she", "her", "hers", "herself", "it", "its", "itself", "they", "them", "their",
        "theirs", "themselves", "what", "which", "who", "whom", "this", "that", "these", "those", "am", "is", "are", "was",
        "were", "be", "been", "being", "have", "has", "had", "having", "do", "does", "did", "doing", "a", "an", "the", "and",
        "but", "if", "or", "because", "as", "until", "while", "of", "at", "by", "for", "with", "about", "against", "between",
        "into", "through", "during", "before", "after", "above", "below", "to", "from", "up", "down", "in", "out", "on", "off",
        "over", "under", "again", "further", "then", "once", "here", "there", "when", "where", "why", "how", "all", "any",
        "both", "each", "few", "more", "most", "other", "some", "such", "no", "nor", "not", "only", "own", "same", "so",
        "than", "too", "very", "s", "t", "can", "will", "just", "don", "should", "now"
    ])
    return [word for word in title.split() if word.lower() not in stop_words]

# Define a function that counts for 10 of the most frequent words in the list of titles
def count_most_frequent_words(titles):
    words = [word for title in titles for word in remove_stopwords(title)]
    word_counts = Counter(words)
    return word_counts.most_common(10)

# Define a function that calculates the fraction of articles containing certain words
def calculate_word_fraction(titles, words):
    total_articles = len(titles)
    word_counts = Counter([word.lower() for title in titles for word in title.split()])
    fractions = {word: word_counts[word.lower()] / total_articles for word in words}
    return fractions

# Define a function that extracts dollar amounts mentioned in the list of titles
def extract_dollar_amounts(titles):
    dollar_regex = r'\$[0-9,]+'
    total_dollars = 0
    for title in titles:
        amounts = re.findall(dollar_regex, title)
        for amount in amounts:
            total_dollars += int(amount.replace('$', '').replace(',', ''))
    return total_dollars

# Define a function that calculates the average sentiment score of the list of titles
def calculate_sentiment(titles):
    analyzer = SentimentIntensityAnalyzer()
    total_sentiment = 0
    for title in titles:
        sentiment = analyzer.polarity_scores(title)['compound']
        total_sentiment += sentiment
    return total_sentiment / len(titles)

# Define main function
def main():
    # Read titles from files
    titles_1918 = read_titles_from_file("titles_1918.txt")
    titles_2020 = read_titles_from_file("titles_2020.txt")

    # Count most frequent words
    most_common_1918 = count_most_frequent_words(titles_1918)
    most_common_2020 = count_most_frequent_words(titles_2020)

    # Define words for word fraction calculation
    words_to_check = ["flu", "virus", "death"]

    # Calculate word fractions
    word_fraction_1918 = calculate_word_fraction(titles_1918, words_to_check)
    word_fraction_2020 = calculate_word_fraction(titles_2020, words_to_check)

    # Count dollar amounts
    total_dollars_1918 = extract_dollar_amounts(titles_1918)
    total_dollars_2020 = extract_dollar_amounts(titles_2020)

    # Calculate sentiment
    average_sentiment_1918 = calculate_sentiment(titles_1918)
    average_sentiment_2020 = calculate_sentiment(titles_2020)

    # Print results
    print("-----------------------")
    print("Most frequent words in 1918")
    print("-----------------------")
    for word, count in most_common_1918:
        print(f"{word}, {count}")
    print("\n-----------------------")
    print("Most frequent words in 2020")
    print("-----------------------")
    for word, count in most_common_2020:
        print(f"{word}, {count}")
    print("\n-----------------------")
    print("Fraction of articles in 1918")
    print("-----------------------")
    for word in words_to_check:
        print(f"{word} {word_fraction_1918[word]:}")
    print("\n-----------------------")
    print("Fraction of articles in 2020")
    print("-----------------------")
    for word in words_to_check:
        print(f"{word} {word_fraction_2020[word]:}")
    print("\n-----------------------")
    print("Dollar amounts")
    print("-----------------------")
    print(f"1918 ${total_dollars_1918:,}")
    print(f"2020 ${total_dollars_2020:,}")
    print("\n-----------------------")
    print("Sentiment 1918")
    print("-----------------------")
    print(f"The average sentiment is {average_sentiment_1918:}")
    print("\n-----------------------")
    print("Sentiment 2020")
    print("-----------------------")
    print(f"The average sentiment is {average_sentiment_2020:}")

main()
